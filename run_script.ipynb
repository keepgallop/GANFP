{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset  for preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully remove file ../../CelebA/.DS_Store\n",
      "../../CelebA/4-MMDGAN/MMD_00089184.png is invalid image, deleted\n",
      "../../CelebA/2-SNGAN/SNGAN_00085763.png is invalid image, deleted\n",
      "../../CelebA/3-CramerGAN/CRAMER_00092090.png is invalid image, deleted\n",
      "split ../../CelebA/4-MMDGAN to ../../CelebA/Train/4-MMDGAN is ready\n",
      "split ../../CelebA/0-Real to ../../CelebA/Train/0-Real is ready\n",
      "split ../../CelebA/2-SNGAN to ../../CelebA/Train/2-SNGAN is ready\n",
      "split ../../CelebA/3-CramerGAN to ../../CelebA/Train/3-CramerGAN is ready\n",
      "split ../../CelebA/1-ProGAN to ../../CelebA/Train/1-ProGAN is ready\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "TEST_PATH = '../../CelebA/'\n",
    "utils.split_dataset(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split ../../LSUN/3-CramerGAN to ../../LSUN/Train/3-CramerGAN is ready\n",
      "split ../../LSUN/1-ProGAN to ../../LSUN/Train/1-ProGAN is ready\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "TEST_PATH = '../../LSUN/'\n",
    "split_dataset(TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "******************* Start training ********************\n",
      "----Cleaning workspace----\n",
      "Successfully remove folder ./.ipynb_checkpoints\n",
      "Done!\n",
      "----Loading model----\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 3)       84        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 163845    \n",
      "=================================================================\n",
      "Total params: 169,961\n",
      "Trainable params: 169,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Done!\n",
      "----Loading data----\n",
      "Training generator summary\n",
      "Found 384997 images belonging to 5 classes.\n",
      "Validation generator summary\n",
      "Found 82500 images belonging to 5 classes.\n",
      "Done!\n",
      "----Training model----\n",
      "Epoch 1/200\n",
      "2020-07-10 22:32:29.288447: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "3007/3007 [==============================] - 2006s 667ms/step - loss: 0.6581 - acc: 0.7346 - val_loss: 0.1976 - val_acc: 0.9303\n",
      "Epoch 2/200\n",
      "3007/3007 [==============================] - 1956s 650ms/step - loss: 0.1081 - acc: 0.9637 - val_loss: 0.0892 - val_acc: 0.9693\n",
      "Epoch 3/200\n",
      "3007/3007 [==============================] - 1880s 625ms/step - loss: 0.0519 - acc: 0.9823 - val_loss: 0.0593 - val_acc: 0.9798\n",
      "Epoch 4/200\n",
      "3007/3007 [==============================] - 1886s 627ms/step - loss: 0.0331 - acc: 0.9885 - val_loss: 0.0474 - val_acc: 0.9841\n",
      "Epoch 5/200\n",
      "3007/3007 [==============================] - 1878s 625ms/step - loss: 0.0225 - acc: 0.9921 - val_loss: 0.0544 - val_acc: 0.9821\n",
      "Epoch 6/200\n",
      "3007/3007 [==============================] - 1878s 625ms/step - loss: 0.0180 - acc: 0.9936 - val_loss: 0.0450 - val_acc: 0.9864\n",
      "Epoch 7/200\n",
      "3007/3007 [==============================] - 1878s 624ms/step - loss: 0.0156 - acc: 0.9944 - val_loss: 0.0385 - val_acc: 0.9885\n",
      "Epoch 8/200\n",
      "3007/3007 [==============================] - 1880s 625ms/step - loss: 0.0123 - acc: 0.9957 - val_loss: 0.0487 - val_acc: 0.9861\n",
      "Epoch 9/200\n",
      "3007/3007 [==============================] - 1875s 623ms/step - loss: 0.0113 - acc: 0.9961 - val_loss: 0.0430 - val_acc: 0.9890\n",
      "Epoch 10/200\n",
      "3007/3007 [==============================] - 1872s 622ms/step - loss: 0.0105 - acc: 0.9963 - val_loss: 0.0408 - val_acc: 0.9895\n",
      "Epoch 11/200\n",
      "3007/3007 [==============================] - 1869s 622ms/step - loss: 0.0095 - acc: 0.9966 - val_loss: 0.0565 - val_acc: 0.9857\n",
      "Epoch 12/200\n",
      "3007/3007 [==============================] - 1875s 623ms/step - loss: 0.0092 - acc: 0.9968 - val_loss: 0.0458 - val_acc: 0.9881\n",
      "Epoch 13/200\n",
      "3007/3007 [==============================] - 1870s 622ms/step - loss: 0.0083 - acc: 0.9971 - val_loss: 0.0564 - val_acc: 0.9859\n",
      "Epoch 14/200\n",
      "3007/3007 [==============================] - 1874s 623ms/step - loss: 0.0081 - acc: 0.9973 - val_loss: 0.0444 - val_acc: 0.9894\n",
      "Epoch 15/200\n",
      "3007/3007 [==============================] - 1889s 628ms/step - loss: 0.0075 - acc: 0.9974 - val_loss: 0.0695 - val_acc: 0.9862\n",
      "Epoch 16/200\n",
      "3007/3007 [==============================] - 1902s 633ms/step - loss: 0.0074 - acc: 0.9974 - val_loss: 0.0401 - val_acc: 0.9909\n",
      "Epoch 17/200\n",
      "3007/3007 [==============================] - 1895s 630ms/step - loss: 0.0073 - acc: 0.9976 - val_loss: 0.0715 - val_acc: 0.9849\n",
      "Done!\n",
      "model files save to ./logs/CelebA-rgb-raw-rTrue-lFalse-none-log.pkl\n",
      "******************* End training ********************\n",
      "Using TensorFlow backend.\n",
      "******************* Start training ********************\n",
      "----Cleaning workspace----\n",
      "Successfully remove folder ./.ipynb_checkpoints\n",
      "Done!\n",
      "----Loading model----\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 3)       84        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 163845    \n",
      "=================================================================\n",
      "Total params: 169,961\n",
      "Trainable params: 169,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Done!\n",
      "----Loading data----\n",
      "Training generator summary\n",
      "Found 384997 images belonging to 5 classes.\n",
      "Validation generator summary\n",
      "Found 82500 images belonging to 5 classes.\n",
      "Done!\n",
      "----Training model----\n",
      "Epoch 1/200\n",
      "2020-07-11 07:28:54.820108: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "3007/3007 [==============================] - 1972s 656ms/step - loss: 0.2240 - acc: 0.9152 - val_loss: 0.0588 - val_acc: 0.9793\n",
      "Epoch 2/200\n",
      " 800/3007 [======>.......................] - ETA: 21:29 - loss: 0.0629 - acc: 0.9781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3007/3007 [==============================] - 2042s 679ms/step - loss: 0.0344 - acc: 0.9880 - val_loss: 0.0287 - val_acc: 0.9906\n",
      "Epoch 4/200\n",
      "3007/3007 [==============================] - 2057s 684ms/step - loss: 0.0257 - acc: 0.9912 - val_loss: 0.0254 - val_acc: 0.9919\n",
      "Epoch 5/200\n",
      "3007/3007 [==============================] - 1973s 656ms/step - loss: 0.0205 - acc: 0.9929 - val_loss: 0.0319 - val_acc: 0.9895\n",
      "Epoch 6/200\n",
      "3007/3007 [==============================] - 1993s 663ms/step - loss: 0.0167 - acc: 0.9943 - val_loss: 0.0284 - val_acc: 0.9906\n",
      "Epoch 7/200\n",
      "3007/3007 [==============================] - 2068s 688ms/step - loss: 0.0143 - acc: 0.9950 - val_loss: 0.0331 - val_acc: 0.9892\n",
      "Epoch 8/200\n",
      "3007/3007 [==============================] - 2060s 685ms/step - loss: 0.0124 - acc: 0.9957 - val_loss: 0.0308 - val_acc: 0.9908\n",
      "Epoch 9/200\n",
      "3007/3007 [==============================] - 2162s 719ms/step - loss: 0.0112 - acc: 0.9962 - val_loss: 0.0283 - val_acc: 0.9921\n",
      "Done!\n",
      "model files save to ./logs/CelebA-rgb-dct-rFalse-lTrue-fz-log.pkl\n",
      "******************* End training ********************\n",
      "terminate called without an active exception\n",
      "Using TensorFlow backend.\n",
      "******************* Start training ********************\n",
      "----Cleaning workspace----\n",
      "Successfully remove folder ./.ipynb_checkpoints\n",
      "Done!\n",
      "----Loading model----\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 3)       84        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 163845    \n",
      "=================================================================\n",
      "Total params: 169,961\n",
      "Trainable params: 169,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Done!\n",
      "----Loading data----\n",
      "Training generator summary\n",
      "Found 384997 images belonging to 5 classes.\n",
      "Validation generator summary\n",
      "Found 82500 images belonging to 5 classes.\n",
      "Done!\n",
      "----Training model----\n",
      "Epoch 1/200\n",
      "2020-07-11 12:34:48.311393: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "3007/3007 [==============================] - 2103s 699ms/step - loss: 0.2612 - acc: 0.9020 - val_loss: 0.0272 - val_acc: 0.9917\n",
      "Epoch 2/200\n",
      "3007/3007 [==============================] - 2063s 686ms/step - loss: 0.0227 - acc: 0.9928 - val_loss: 0.0145 - val_acc: 0.9957\n",
      "Epoch 3/200\n",
      "3007/3007 [==============================] - 1965s 653ms/step - loss: 0.0111 - acc: 0.9964 - val_loss: 0.0073 - val_acc: 0.9979\n",
      "Epoch 4/200\n",
      "3007/3007 [==============================] - 2025s 673ms/step - loss: 0.0075 - acc: 0.9975 - val_loss: 0.0382 - val_acc: 0.9867\n",
      "Epoch 5/200\n",
      "3007/3007 [==============================] - 2042s 679ms/step - loss: 0.0062 - acc: 0.9979 - val_loss: 0.0076 - val_acc: 0.9979\n",
      "Epoch 6/200\n",
      "3007/3007 [==============================] - 2059s 685ms/step - loss: 0.0057 - acc: 0.9982 - val_loss: 0.0058 - val_acc: 0.9981\n",
      "Epoch 7/200\n",
      "3007/3007 [==============================] - 1953s 649ms/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0066 - val_acc: 0.9982\n",
      "Epoch 8/200\n",
      "3007/3007 [==============================] - 1928s 641ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0138 - val_acc: 0.9962\n",
      "Epoch 9/200\n",
      "3007/3007 [==============================] - 1938s 644ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0187 - val_acc: 0.9952\n",
      "Epoch 10/200\n",
      "3007/3007 [==============================] - 1946s 647ms/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0151 - val_acc: 0.9962\n",
      "Epoch 11/200\n",
      "3007/3007 [==============================] - 1951s 649ms/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0162 - val_acc: 0.9957\n",
      "Done!\n",
      "model files save to ./logs/CelebA-ycc-raw-rTrue-lFalse-fz-log.pkl\n",
      "******************* End training ********************\n",
      "Using TensorFlow backend.\n",
      "******************* Start training ********************\n",
      "----Cleaning workspace----\n",
      "Successfully remove folder ./.ipynb_checkpoints\n",
      "Done!\n",
      "----Loading model----\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 3)       84        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 163845    \n",
      "=================================================================\n",
      "Total params: 169,961\n",
      "Trainable params: 169,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Done!\n",
      "----Loading data----\n",
      "Training generator summary\n",
      "Found 384997 images belonging to 5 classes.\n",
      "Validation generator summary\n",
      "Found 82500 images belonging to 5 classes.\n",
      "Done!\n",
      "----Training model----\n",
      "Epoch 1/200\n",
      "2020-07-11 18:41:25.500877: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "3007/3007 [==============================] - 2430s 808ms/step - loss: 0.0925 - acc: 0.9651 - val_loss: 0.0297 - val_acc: 0.9898\n",
      "Epoch 2/200\n",
      "3007/3007 [==============================] - 2237s 744ms/step - loss: 0.0208 - acc: 0.9929 - val_loss: 0.0164 - val_acc: 0.9947\n",
      "Epoch 3/200\n",
      "3007/3007 [==============================] - 2281s 759ms/step - loss: 0.0153 - acc: 0.9949 - val_loss: 0.0231 - val_acc: 0.9925\n",
      "Epoch 4/200\n",
      "3007/3007 [==============================] - 2252s 749ms/step - loss: 0.0117 - acc: 0.9960 - val_loss: 0.0177 - val_acc: 0.9947\n",
      "Epoch 5/200\n",
      "3007/3007 [==============================] - 2212s 735ms/step - loss: 0.0092 - acc: 0.9968 - val_loss: 0.0159 - val_acc: 0.9951\n",
      "Epoch 6/200\n",
      "3007/3007 [==============================] - 2230s 742ms/step - loss: 0.0084 - acc: 0.9972 - val_loss: 0.0143 - val_acc: 0.9959\n",
      "Epoch 7/200\n",
      "3007/3007 [==============================] - 2280s 758ms/step - loss: 0.0071 - acc: 0.9976 - val_loss: 0.0165 - val_acc: 0.9955\n",
      "Epoch 8/200\n",
      "3007/3007 [==============================] - 2414s 803ms/step - loss: 0.0064 - acc: 0.9979 - val_loss: 0.0152 - val_acc: 0.9962\n",
      "Epoch 9/200\n",
      "3007/3007 [==============================] - 2281s 759ms/step - loss: 0.0062 - acc: 0.9980 - val_loss: 0.0176 - val_acc: 0.9955\n",
      "Done!\n",
      "model files save to ./logs/CelebA-ycc-dct-rFalse-lTrue-fz-log.pkl\n",
      "******************* End training ********************\n",
      "Using TensorFlow backend.\n",
      "******************* Start training ********************\n",
      "----Cleaning workspace----\n",
      "Successfully remove folder ./.ipynb_checkpoints\n",
      "Done!\n",
      "----Loading model----\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 3)       30        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 163845    \n",
      "=================================================================\n",
      "Total params: 169,907\n",
      "Trainable params: 169,907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Done!\n",
      "----Loading data----\n",
      "Training generator summary\n",
      "Found 384997 images belonging to 5 classes.\n",
      "Validation generator summary\n",
      "Found 82500 images belonging to 5 classes.\n",
      "Done!\n",
      "----Training model----\n",
      "Epoch 1/200\n",
      "2020-07-12 00:25:23.342681: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "  26/3007 [..............................] - ETA: 27:55 - loss: 1.6209 - acc: 0.2100^C\n",
      "Using TensorFlow backend.\n",
      "******************* Start training ********************\n",
      "----Cleaning workspace----\n",
      "Done!\n",
      "----Loading model----\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 3)       30        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 163845    \n",
      "=================================================================\n",
      "Total params: 169,907\n",
      "Trainable params: 169,907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Done!\n",
      "----Loading data----\n",
      "Training generator summary\n",
      "Using TensorFlow backend.\n",
      "******************* Start training ********************\n",
      "----Cleaning workspace----\n",
      "Done!\n",
      "----Loading model----\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 3)       84        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 163845    \n",
      "=================================================================\n",
      "Total params: 169,961\n",
      "Trainable params: 169,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Done!\n",
      "----Loading data----\n",
      "Training generator summary\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"run.py\", line 8, in <module>\n",
      "    import joblib\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/__init__.py\", line 120, in <module>\n",
      "    from .parallel import Parallel\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/parallel.py\", line 26, in <module>\n",
      "    from ._parallel_backends import (FallbackToBackend, MultiprocessingBackend,\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 17, in <module>\n",
      "    from .pool import MemmappingPool\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/pool.py\", line 31, in <module>\n",
      "    from ._memmapping_reducer import get_memmapping_reducers\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/_memmapping_reducer.py\", line 37, in <module>\n",
      "    from .externals.loky.backend import resource_tracker\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/externals/loky/__init__.py\", line 6, in <module>\n",
      "    from ._base import Executor, Future\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/externals/loky/_base.py\", line 22, in <module>\n",
      "    from concurrent.futures import wait, as_completed\n",
      "  File \"/usr/lib/python3.6/concurrent/futures/__init__.py\", line 17, in <module>\n",
      "    from concurrent.futures.process import ProcessPoolExecutor\n",
      "  File \"/usr/lib/python3.6/concurrent/futures/process.py\", line 55, in <module>\n",
      "    from multiprocessing.connection import wait\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 779, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 487, in _compile_bytecode\n",
      "KeyboardInterrupt\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"run.py\", line 8, in <module>\n",
      "    import joblib\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/memory.py\", line 16, in <module>\n",
      "    import pydoc\n",
      "  File \"/usr/lib/python3.6/pydoc.py\", line 63, in <module>\n",
      "    import inspect\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 35, in <module>\n",
      "    import ast\n",
      "  File \"/usr/lib/python3.6/ast.py\", line 27, in <module>\n",
      "    from _ast import *\n",
      "KeyboardInterrupt\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"run.py\", line 8, in <module>\n",
      "    import joblib\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/memory.py\", line 29, in <module>\n",
      "    from .func_inspect import get_func_code, get_func_name, filter_args\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/func_inspect.py\", line 18, in <module>\n",
      "    from .logger import pformat\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/logger.py\", line 20, in <module>\n",
      "    from .disk import mkdirp\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/disk.py\", line 17, in <module>\n",
      "    from multiprocessing import util\n",
      "  File \"/usr/lib/python3.6/multiprocessing/__init__.py\", line 16, in <module>\n",
      "    from . import context\n",
      "  File \"/usr/lib/python3.6/multiprocessing/context.py\", line 5, in <module>\n",
      "    from . import process\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 331, in <module>\n",
      "    if name[:3]=='SIG' and '_' not in name:\n",
      "KeyboardInterrupt\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"run.py\", line 8, in <module>\n",
      "    import joblib\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/memory.py\", line 16, in <module>\n",
      "    import pydoc\n",
      "  File \"/usr/lib/python3.6/pydoc.py\", line 63, in <module>\n",
      "    import inspect\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 41, in <module>\n",
      "    import linecache\n",
      "  File \"/usr/lib/python3.6/linecache.py\", line 11, in <module>\n",
      "    import tokenize\n",
      "  File \"/usr/lib/python3.6/tokenize.py\", line 37, in <module>\n",
      "    cookie_re = re.compile(r'^[ \\t\\f]*#.*?coding[:=][ \\t]*([-\\w.]+)', re.ASCII)\n",
      "  File \"/usr/lib/python3.6/re.py\", line 233, in compile\n",
      "    return _compile(pattern, flags)\n",
      "  File \"/usr/lib/python3.6/re.py\", line 301, in _compile\n",
      "    p = sre_compile.compile(pattern, flags)\n",
      "  File \"/usr/lib/python3.6/sre_compile.py\", line 566, in compile\n",
      "    code = _code(p, flags)\n",
      "  File \"/usr/lib/python3.6/sre_compile.py\", line 551, in _code\n",
      "    _compile(code, p.data, flags)\n",
      "  File \"/usr/lib/python3.6/sre_compile.py\", line 72, in _compile\n",
      "    if (flags & SRE_FLAG_IGNORECASE and\n",
      "KeyboardInterrupt\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"run.py\", line 8, in <module>\n",
      "    import joblib\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/memory.py\", line 29, in <module>\n",
      "    from .func_inspect import get_func_code, get_func_name, filter_args\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/func_inspect.py\", line 18, in <module>\n",
      "    from .logger import pformat\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/logger.py\", line 20, in <module>\n",
      "    from .disk import mkdirp\n",
      "  File \"/home/mist/.local/lib/python3.6/site-packages/joblib/disk.py\", line 17, in <module>\n",
      "    from multiprocessing import util\n",
      "  File \"/usr/lib/python3.6/multiprocessing/__init__.py\", line 16, in <module>\n",
      "    from . import context\n",
      "  File \"/usr/lib/python3.6/multiprocessing/context.py\", line 6, in <module>\n",
      "    from . import reduction\n",
      "  File \"/usr/lib/python3.6/multiprocessing/reduction.py\", line 16, in <module>\n",
      "    import socket\n",
      "  File \"/usr/lib/python3.6/socket.py\", line 76, in <module>\n",
      "    lambda C: C.isupper() and C.startswith('AF_'))\n",
      "  File \"/usr/lib/python3.6/enum.py\", line 634, in _convert\n",
      "    cls = cls(name, members, module=module)\n",
      "  File \"/usr/lib/python3.6/enum.py\", line 295, in __call__\n",
      "    return cls._create_(value, names, module=module, qualname=qualname, type=type, start=start)\n",
      "  File \"/usr/lib/python3.6/enum.py\", line 401, in _create_\n",
      "    enum_class = metacls.__new__(metacls, class_name, bases, classdict)\n",
      "  File \"/usr/lib/python3.6/enum.py\", line 160, in __new__\n",
      "    dynamic_attributes = {k for c in enum_class.mro()\n",
      "  File \"/usr/lib/python3.6/enum.py\", line 162, in <setcomp>\n",
      "    if isinstance(v, DynamicClassAttribute)}\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, traindatasetpath, validdatasetpath in zip(['CelebA', 'LSUN'],\n",
    "                                                            [\"../../CelebA/Train\", \"../../LSUN/Train\"], \n",
    "                                                            [\"../../CelebA/Valid\", \"../../LSUN/Valid\"]):\n",
    "    !python3 run.py -a 'training' -d {dataset_name} -c 'rgb' -f 'raw' -n 'none' -r -tp {traindatasetpath} -vp {validdatasetpath}\n",
    "    !python3 run.py -a 'training' -d {dataset_name} -c 'rgb' -f 'dct' -n 'fz' -l -tp {traindatasetpath} -vp {validdatasetpath}\n",
    "    !python3 run.py -a 'training' -d {dataset_name} -c 'ycc' -f 'raw' -n 'fz' -r -tp {traindatasetpath} -vp {validdatasetpath}\n",
    "    !python3 run.py -a 'training' -d {dataset_name} -c 'ycc' -f 'dct' -n 'fz' -l -tp {traindatasetpath} -vp {validdatasetpath}\n",
    "    !python3 run.py -a 'training' -d {dataset_name} -c 'gray' -f 'raw' -n 'none' -r -tp {traindatasetpath} -vp {validdatasetpath}\n",
    "    !python3 run.py -a 'training' -d {dataset_name} -c 'gray' -f 'dct' -n 'fz' -l -tp {traindatasetpath} -vp {validdatasetpath}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSUN - ToDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "******************* Start evaluation ********************\n",
      "----Cleaning workspace----\n",
      "Successfully remove folder ./.ipynb_checkpoints\n",
      "Done!\n",
      "----Ploting training logs----\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "Log analysis done. Saved to ./results/training_logs_CelebA.eps\n",
      "Done!\n",
      "----Evaluating models----\n",
      "Found 82500 images belonging to 5 classes.\n",
      "2020-07-18 00:12:00.941059: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "645/645 [==============================] - 518s 802ms/step\n",
      "Found 82500 images belonging to 5 classes.\n",
      "645/645 [==============================] - 341s 529ms/step\n",
      "Found 82500 images belonging to 5 classes.\n",
      "645/645 [==============================] - 406s 630ms/step\n",
      "Found 82500 images belonging to 5 classes.\n",
      "645/645 [==============================] - 389s 602ms/step\n",
      "Found 82500 images belonging to 5 classes.\n",
      "645/645 [==============================] - 185s 286ms/step\n",
      "Found 82500 images belonging to 5 classes.\n",
      "645/645 [==============================] - 395s 613ms/step\n",
      "Found 82500 images belonging to 5 classes.\n",
      "645/645 [==============================] - 143s 222ms/step\n",
      "Save prediction results to ./results/CelebA_eval_result.pkl\n",
      "Done!\n",
      "----Analyzing results----\n",
      "Update prediction results to ./results/CelebA_eval_result.pkl\n",
      "Done!\n",
      "******************* End evaluation ********************\n"
     ]
    }
   ],
   "source": [
    "!python3 run.py 'evaluation' -p -lp \"./logs/\" -rp \"./results/\" -mp \"./model/\" -tp \"../../CelebA/Test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSUN - ToDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "******************* Start evaluation ********************\n",
      "----Cleaning workspace----\n",
      "Successfully remove folder ./.ipynb_checkpoints\n",
      "Done!\n",
      "----Visualize models----\n",
      "Current model is CelebA-ycc-dct-rFalse-lTrue-fz-model.06-0.01.h5\n",
      "2020-07-18 01:31:54.690614: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "Found 2500 images belonging to 5 classes.\n",
      "12/2500\r"
     ]
    }
   ],
   "source": [
    "!python3 run.py \"visualization\" -rp \"./results/\" -mp \"./model/\" -tp \"../../CelebA/Visual/\" -c 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# just demos for testing on my local machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "******************* Start training ********************\n",
      "----Cleaning workspace----\n",
      "Successfully remove folder ./.ipynb_checkpoints\n",
      "Done!\n",
      "----Loading model----\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 3)       84        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 163845    \n",
      "=================================================================\n",
      "Total params: 169,961\n",
      "Trainable params: 169,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Done!\n",
      "----Loading data----\n",
      "Training generator summary\n",
      "Found 3500 images belonging to 5 classes.\n",
      "Validation generator summary\n",
      "Found 750 images belonging to 5 classes.\n",
      "Done!\n",
      "----Training model----\n",
      "Epoch 1/200\n",
      "2020-07-16 18:37:28.431595: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\n",
      " 4/27 [===>..........................] - ETA: 22s - loss: 2.2205 - acc: 0.2090^C\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'CelebA'\n",
    "traindatasetpath = './dataset/CelebA/Train/'\n",
    "validdatasetpath = './dataset/CelebA/Valid/'\n",
    "!python3 run.py 'training' -d {dataset_name} -c 'rgb' -f 'dct' -n 'fz' -l -tp {traindatasetpath} -vp {validdatasetpath}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "******************* Start evaluation ********************\n",
      "----Ploting training logs----\n",
      "Figure(2000x400)\n",
      "Log analysis done. Saved to ./results/training_logs_CelebA.eps\n",
      "Done!\n",
      "----Evaluating models----\n",
      "Found 754 images belonging to 5 classes.\n",
      "2020-07-17 00:52:56.882563: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\n",
      "6/6 [==============================] - 4s 672ms/step\n",
      "Found 754 images belonging to 5 classes.\n",
      "6/6 [==============================] - 3s 457ms/step\n",
      "Found 754 images belonging to 5 classes.\n",
      "6/6 [==============================] - 4s 635ms/step\n",
      "Found 754 images belonging to 5 classes.\n",
      "6/6 [==============================] - 4s 641ms/step\n",
      "Found 754 images belonging to 5 classes.\n",
      "6/6 [==============================] - 4s 650ms/step\n",
      "Found 754 images belonging to 5 classes.\n",
      "6/6 [==============================] - 4s 660ms/step\n",
      "Found 754 images belonging to 5 classes.\n",
      "6/6 [==============================] - 3s 475ms/step\n",
      "Found 754 images belonging to 5 classes.\n",
      "6/6 [==============================] - 3s 553ms/step\n",
      "Save prediction results to ./results/CelebA_eval_result.pkl\n",
      "Done!\n",
      "----Analyzing results----\n",
      "Update prediction results to ./results/CelebA_eval_result.pkl\n",
      "******************* End evaluation ********************\n"
     ]
    }
   ],
   "source": [
    "!python3 run.py 'evaluation' -p -lp \"./logs/\" -rp \"./results/\" -mp \"./model/\" -tp \"./dataset/CelebA/Test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "******************* Start evaluation ********************\n",
      "----Cleaning workspace----\n",
      "Successfully remove file ./.DS_Store\n",
      "Successfully remove file ./analysis/.DS_Store\n",
      "Successfully remove folder ./.ipynb_checkpoints\n",
      "Done!\n",
      "----Visualize models----\n",
      "------ Path to save fingerprint: ./analysis/results/fingerprints -----\n",
      "------ Current model is CelebA-ycc-dct-rFalse-lTrue-fz-model.08-0.02.h5 ------\n",
      "2020-07-29 20:25:59.130641: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\n",
      "Found 5000 validated image filenames belonging to 5 classes.\n",
      "1/5000, time = 8.845134019851685\n",
      "2/5000, time = 8.897911787033081\n",
      "3/5000, time = 9.154801845550537\n",
      "4/5000, time = 9.943887948989868\n",
      "5/5000, time = 9.517799139022827\n",
      "6/5000, time = 9.804452657699585\n",
      "7/5000, time = 9.516610860824585\n",
      "8/5000, time = 9.65056300163269\n",
      "9/5000, time = 10.006566047668457\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"run.py\", line 599, in <module>\n",
      "    main()\n",
      "  File \"run.py\", line 594, in main\n",
      "    start_visualization_workflow(args)\n",
      "  File \"run.py\", line 488, in start_visualization_workflow\n",
      "    vis_rep_model(args.model_path, args.vis_dataset_path, args.result_path, args.num_per_class)\n",
      "  File \"run.py\", line 298, in vis_rep_model\n",
      "    f_mask = deconvnet.compute()\n",
      "  File \"/Users/leoch/ProjectsTMP/GANFF/visualization.py\", line 188, in compute\n",
      "    gate_b)\n",
      "  File \"/Users/leoch/ProjectsTMP/GANFF/visualization.py\", line 134, in guided_backprop_adjacent\n",
      "    gate_f = K.cast(values_prev > 0., 'float32')\n",
      "  File \"/Users/leoch/ProjectsTMP/GANFF/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 957, in cast\n",
      "    return tf.cast(x, dtype)\n",
      "  File \"/Users/leoch/ProjectsTMP/GANFF/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 755, in cast\n",
      "    x = ops.convert_to_tensor(x, name=\"x\")\n",
      "  File \"/Users/leoch/ProjectsTMP/GANFF/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 932, in convert_to_tensor\n",
      "    as_ref=False)\n",
      "  File \"/Users/leoch/ProjectsTMP/GANFF/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1022, in internal_convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/leoch/ProjectsTMP/GANFF/venv/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 233, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/Users/leoch/ProjectsTMP/GANFF/venv/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 212, in constant\n",
      "    value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n",
      "  File \"/Users/leoch/ProjectsTMP/GANFF/venv/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\", line 513, in make_tensor_proto\n",
      "    append_fn(tensor_proto, proto_values)\n",
      "  File \"tensorflow/python/framework/fast_tensor_util.pyx\", line 115, in tensorflow.python.framework.fast_tensor_util.AppendBoolArrayToTensorProto\n",
      "  File \"<__array_function__ internals>\", line 6, in asscalar\n",
      "  File \"/Users/leoch/ProjectsTMP/GANFF/venv/lib/python3.6/site-packages/numpy/lib/type_check.py\", line 581, in asscalar\n",
      "    return a.item()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 run.py 'visualization' -rp \"./analysis/results/\" -mp \"./analysis/model/\" -tp \"./analysis/dataset/repre/CelebA/\" -n 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
